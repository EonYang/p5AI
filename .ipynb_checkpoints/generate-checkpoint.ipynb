{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My plan is \n",
    "\n",
    "// function 1  generate\n",
    "1. generate 100 chars, save them in sketch.js\n",
    "\n",
    "// function 2   check loop\n",
    "2. use chrome driver and selenium to run the sketch website\n",
    "\n",
    "3. find body, check it's attribute\n",
    "\n",
    "// function 3   delete one line.\n",
    "4. if there is a \"js error\", delete one line.\n",
    "\n",
    "5. do it repeately, until there is no error.\n",
    "\n",
    "6. call function 1 again\n",
    "\n",
    "7. call function 3 again\n",
    "\n",
    "so, function 2 will call function 1 & 3.\n",
    "\n",
    "no error -- 1\n",
    "\n",
    "error --3\n",
    "\n",
    "\n",
    "right now:\n",
    "\n",
    "## Questions:\n",
    "\n",
    "- [ ] file.open with \"w\" flag will make the file empty   wb\n",
    "\n",
    "\n",
    "- [ ] The generated code looks terrible, can I integrate Reinforcement Learning so it can produce non-error codes?\n",
    "\n",
    "\n",
    "- [ ] how to keep tf session alive as much as possible, so It's won't need to load model every time. will this it be faster?   \n",
    "\n",
    "  - [ ] is my solution correct?\n",
    "  \n",
    "- [ ] if I call `generate()` then call `checkError()`, will I encounter some async issue?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"3b78d8c8ae298f7987f160a5beb31340\", element=\"0.4685503330610292-1\")>\n",
      "true\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "    \n",
    "\n",
    "host_url = 'http://127.0.0.1:8000/'\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--window-size=1024x800\")\n",
    "    \n",
    "\n",
    "chrome_driver_path = os.path.join(os.getcwd(), \"chromedriver\")\n",
    "driver = webdriver.Chrome(options=chrome_options, executable_path=chrome_driver_path)\n",
    "\n",
    "def getJSError():\n",
    "    r = false\n",
    "    driver.get(host_url)\n",
    "    body = driver.find_element_by_tag_name(\"body\")\n",
    "    if body.get_attribute(\"jserror\") == 'true':\n",
    "        r = true\n",
    "    driver.close()\n",
    "    return r\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnnlm/softmax_w already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/YANG/dev/myGithub/p5AI/model.py\", line 48, in __init__\n    [args.rnn_size, args.vocab_size])\n  File \"<ipython-input-1-5bf8648ce7ec>\", line 91, in <module>\n    model = Model(saved_args, training=False)\n  File \"/Users/YANG/.pyenv/versions/3.5.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f99404612b1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprime\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;31m# with tf.Session() as sess:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/myGithub/p5AI/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, training)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rnnlm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             softmax_w = tf.get_variable(\"softmax_w\",\n\u001b[0;32m---> 48\u001b[0;31m                                         [args.rnn_size, args.vocab_size])\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0msoftmax_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax_b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.5.0/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    859\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 861\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnnlm/softmax_w already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/Users/YANG/dev/myGithub/p5AI/model.py\", line 48, in __init__\n    [args.rnn_size, args.vocab_size])\n  File \"<ipython-input-1-5bf8648ce7ec>\", line 91, in <module>\n    model = Model(saved_args, training=False)\n  File \"/Users/YANG/.pyenv/versions/3.5.0/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "from six import text_type\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from model import Model\n",
    "\n",
    "import os\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "\n",
    "def parseCharArray(charArray):\n",
    "    r = []\n",
    "    string = ''\n",
    "    for char in charArray:\n",
    "        if char != '\\n':\n",
    "            string += char\n",
    "        else:\n",
    "            r.append(string)\n",
    "            string = ''\n",
    "    return r\n",
    "    \n",
    "\n",
    "host_url = 'http://127.0.0.1:8000/'\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--window-size=1024x800\")\n",
    "\n",
    "args = dotdict({'n':1000, 'save_dir': os.path.curdir + '/model/', 'prime':'', 'sample':1 })\n",
    "\n",
    "model_dir = os.path.curdir + '/model/'\n",
    "\n",
    "sketch_path = './p5template/sketch.js'\n",
    "    \n",
    "\n",
    "chrome_driver_path = os.path.join(os.getcwd(), \"chromedriver\")\n",
    "driver = webdriver.Chrome(options=chrome_options, executable_path=chrome_driver_path)\n",
    "\n",
    "def getJSError():\n",
    "    r = False\n",
    "    driver.get(host_url)\n",
    "    body = driver.find_element_by_tag_name(\"body\")\n",
    "    if body.get_attribute(\"jserror\") == 'true':\n",
    "        r = True\n",
    "    driver.close()\n",
    "    return r\n",
    "          \n",
    "\n",
    "def generate(num):\n",
    "    newLines = parseCharArray(model.sample(sess, chars, vocab, num, args.prime,\n",
    "                       args.sample))\n",
    "    content.extend(newLines)\n",
    "    print(content)\n",
    "\n",
    "    file = open(sketch_path, \"w\")\n",
    "    file.write(\"\\n\".join(content))\n",
    "    file.close()\n",
    "\n",
    "def removeOne():\n",
    "    with open(sketch_path) as sketch:\n",
    "        content = sketch.read().splitlines() \n",
    "\n",
    "    content.pop()\n",
    "    file = open(sketch_path, \"w\")\n",
    "\n",
    "    file.write(\"\\n\".join(content))\n",
    "    file.close()\n",
    "\n",
    "with open(sketch_path) as sketch:\n",
    "    content = sketch.read().splitlines() \n",
    "with open(os.path.join(model_dir, 'config.pkl'), 'rb') as f:\n",
    "    saved_args = cPickle.load(f)\n",
    "with open(os.path.join(model_dir, 'chars_vocab.pkl'), 'rb') as f:\n",
    "    chars, vocab = cPickle.load(f)\n",
    "#Use most frequent char if no prime is given\n",
    "if args.prime == '':\n",
    "    args.prime = chars[0]\n",
    "model = Model(saved_args, training=False)\n",
    "# with tf.Session() as sess:\n",
    "   \n",
    "\n",
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run()\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "ckpt = tf.train.get_checkpoint_state(args.save_dir)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    while True:\n",
    "        if getJSError() == True:\n",
    "            removeOne()\n",
    "        else:\n",
    "            generate(100)\n",
    "\n",
    "sess.close()\n",
    "        \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
